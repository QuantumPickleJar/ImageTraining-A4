# ImageTraining-A4
<h2>Prerequisites</h2>
<b>Required Packages: (fetch with <code>pip install</code>)</b>
<ul>
  <ol><code>keras</code></ol>
  <ol><code>tensorflow</code></ol>
  <ol><code>jupyter-notebook</code></ol>
  <ol><code>scikit</code></ol>
</ul>



<h1>FNIST.ipynb</h1>
<h3>Purpose:</h3> 
<p>Experiment with training several binary classifiers in just a few
clicks. You can tweak the modelâ€™s architecture and hyperparameters to get some understanding
on how neural networks work.</p>

<b>TensorFlow Playground:</b> https://playground.tensorflow.org/
<ol>
  <li>Try training the neural network by clicking the run button (top left).</li>
  <li>Try replacing the tanh activation function with the reLU function and train the
          network again.</li>
  <li>Modify the network architecture to have just one hidden layer with three neurons.</br>
         Train it multiple times (to reset the network weights, click the reset button).</li>
  <li>Remove one neuron to keep just two. Retrain the network.</li>
  <li>Set the number of neurons to eight and train the network several times.</li></ol>
 
<h1>MNIST.ipynb (WIP) </h1>
<h3>Important:</h3>
<p>Load data with <code>keras.datasets.mnist.load_data()</code></p>
<p>We will train a deep multilayer Neural Network on the MNIST dataset. 
The MNIST dataset is a set of images of handwritten digits 0-9, with 
associated target casses numbered as 0-9.</p></br>

<p>We will play around with different layers and hyperparameters.  Then, we'll
train the model on the training set before testing it on the test set. In this
particular example, the splits are already done for us ahead of time.</p>
<h4>Changes</h4>
<ul>
    <li></li>
    <li></li>
    <li></li>
    <li></li>
</ul>

